{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp2: vectorizer variants #\n",
    "\n",
    "Experiment with NB on Climate Change data only.\n",
    "\n",
    "This was originally inspired by Wang  & Manning (2012), \"Baselines and bigrams: Simple, good sentiment and topic classification, ACL 2012. They report that simple Multinomial NB with binary word bigrams is competetive with more complicated approaches like SVM for classification of short text snippets.\n",
    "\n",
    "Results below show that word bigrams indeed work better tha unigrams, but only without binarization!\n",
    "\n",
    "However, character n-grams outperform words, in particular character trigrams without binarization and with a minimun document frequency of 5.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.cross_validation import cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(open('semeval2016-task6-trainingdata.txt'), '\\t', index_col=0)\n",
    "target_data = data[data.Target == 'Climate Change is a Real Concern']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(target_data.Stance, n_folds=5, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(np.zeros(10000,\n",
    "                                dtype=[('analyzer', 'S8'),\n",
    "                                       ('ngram_range', 'S8'),\n",
    "                                       ('lowercase', 'b'),\n",
    "                                       ('binary', 'b'),\n",
    "                                       ('min_df', 'i'),\n",
    "                                       ('macro_f', 'i')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6779    0.8538    0.7557       212\n",
      "       NONE     0.7360    0.5476    0.6280       168\n",
      "\n",
      "avg / total     0.7148    0.6987    0.6854       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5445\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.0667    0.1250        15\n",
      "      FAVOR     0.6855    0.8019    0.7391       212\n",
      "       NONE     0.6918    0.6012    0.6433       168\n",
      "\n",
      "avg / total     0.7001    0.6886    0.6751       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.4321\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6866    0.8679    0.7667       212\n",
      "       NONE     0.7581    0.5595    0.6438       168\n",
      "\n",
      "avg / total     0.7289    0.7114    0.6980       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5500\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.0667    0.1250        15\n",
      "      FAVOR     0.6939    0.8019    0.7440       212\n",
      "       NONE     0.6980    0.6190    0.6562       168\n",
      "\n",
      "avg / total     0.7073    0.6962    0.6831       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.4345\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6667    0.8302    0.7395       212\n",
      "       NONE     0.7031    0.5357    0.6081       168\n",
      "\n",
      "avg / total     0.6948    0.6810    0.6682       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5364\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.0667    0.1250        15\n",
      "      FAVOR     0.6809    0.7547    0.7159       212\n",
      "       NONE     0.6541    0.6190    0.6361       168\n",
      "\n",
      "avg / total     0.6816    0.6709    0.6595       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.4204\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6617    0.8302    0.7364       212\n",
      "       NONE     0.6984    0.5238    0.5986       168\n",
      "\n",
      "avg / total     0.6901    0.6759    0.6625       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5349\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.0667    0.1250        15\n",
      "      FAVOR     0.6736    0.7594    0.7140       212\n",
      "       NONE     0.6516    0.6012    0.6254       168\n",
      "\n",
      "avg / total     0.6767    0.6658    0.6539       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.4195\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6156    0.8538    0.7154       212\n",
      "       NONE     0.6531    0.3810    0.4812       168\n",
      "\n",
      "avg / total     0.6462    0.6278    0.6013       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5244\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.5000    0.0667    0.1176        15\n",
      "      FAVOR     0.5719    0.8066    0.6693       212\n",
      "       NONE     0.5426    0.3036    0.3893       168\n",
      "\n",
      "avg / total     0.5567    0.5646    0.5293       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.3935\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6115    0.8538    0.7126       212\n",
      "       NONE     0.6458    0.3690    0.4697       168\n",
      "\n",
      "avg / total     0.6408    0.6228    0.5949       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5230\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.5000    0.0667    0.1176        15\n",
      "      FAVOR     0.5686    0.8019    0.6654       212\n",
      "       NONE     0.5319    0.2976    0.3817       168\n",
      "\n",
      "avg / total     0.5504    0.5595    0.5239       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.3915\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6213    0.8821    0.7290       212\n",
      "       NONE     0.6923    0.3750    0.4865       168\n",
      "\n",
      "avg / total     0.6659    0.6405    0.6109       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5312\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.0667    0.1250        15\n",
      "      FAVOR     0.5613    0.8208    0.6667       212\n",
      "       NONE     0.5119    0.2560    0.3413       168\n",
      "\n",
      "avg / total     0.5569    0.5519    0.5077       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.3958\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2667    0.4211        15\n",
      "      FAVOR     0.6233    0.8821    0.7305       212\n",
      "       NONE     0.6923    0.3750    0.4865       168\n",
      "\n",
      "avg / total     0.6670    0.6430    0.6149       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5758\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.0667    0.1250        15\n",
      "      FAVOR     0.5631    0.8208    0.6679       212\n",
      "       NONE     0.5176    0.2619    0.3478       168\n",
      "\n",
      "avg / total     0.5604    0.5544    0.5112       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.3965\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6525    0.8679    0.7449       212\n",
      "       NONE     0.7364    0.4821    0.5827       168\n",
      "\n",
      "avg / total     0.7014    0.6785    0.6603       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5391\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.0667    0.1250        15\n",
      "      FAVOR     0.7021    0.7783    0.7383       212\n",
      "       NONE     0.6792    0.6429    0.6606       168\n",
      "\n",
      "avg / total     0.7037    0.6937    0.6819       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.4316\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6572    0.8774    0.7515       212\n",
      "       NONE     0.7431    0.4821    0.5848       168\n",
      "\n",
      "avg / total     0.7068    0.6835    0.6647       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5424\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.0667    0.1250        15\n",
      "      FAVOR     0.6888    0.7830    0.7329       212\n",
      "       NONE     0.6797    0.6190    0.6480       168\n",
      "\n",
      "avg / total     0.6968    0.6861    0.6737       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.4289\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6754    0.8538    0.7542       212\n",
      "       NONE     0.7339    0.5417    0.6233       168\n",
      "\n",
      "avg / total     0.7126    0.6962    0.6825       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5438\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.0667    0.1250        15\n",
      "      FAVOR     0.6947    0.7406    0.7169       212\n",
      "       NONE     0.6488    0.6488    0.6488       168\n",
      "\n",
      "avg / total     0.6868    0.6759    0.6655       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.4209\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6703    0.8726    0.7582       212\n",
      "       NONE     0.7500    0.5179    0.6127       168\n",
      "\n",
      "avg / total     0.7167    0.6962    0.6802       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5458\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.0667    0.1250        15\n",
      "      FAVOR     0.6897    0.7547    0.7207       212\n",
      "       NONE     0.6605    0.6369    0.6485       168\n",
      "\n",
      "avg / total     0.6890    0.6785    0.6674       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.4229\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.0667    0.1250        15\n",
      "      FAVOR     0.6486    0.7925    0.7134       212\n",
      "       NONE     0.6519    0.5238    0.5809       168\n",
      "\n",
      "avg / total     0.6634    0.6506    0.6347       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.4192\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6490    0.7500    0.6958       212\n",
      "       NONE     0.6259    0.5476    0.5841       168\n",
      "\n",
      "avg / total     0.6525    0.6430    0.6346       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5146\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6545    0.7594    0.7031       212\n",
      "       NONE     0.6438    0.5595    0.5987       168\n",
      "\n",
      "avg / total     0.6631    0.6532    0.6446       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5182\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6653    0.7500    0.7051       212\n",
      "       NONE     0.6405    0.5833    0.6106       168\n",
      "\n",
      "avg / total     0.6675    0.6582    0.6508       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5192\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=10,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2667    0.4211        15\n",
      "      FAVOR     0.6552    0.7170    0.6847       212\n",
      "       NONE     0.6101    0.5774    0.5933       168\n",
      "\n",
      "avg / total     0.6491    0.6405    0.6358       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5529\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.0667    0.1250        15\n",
      "      FAVOR     0.6523    0.7877    0.7137       212\n",
      "       NONE     0.6594    0.5417    0.5948       168\n",
      "\n",
      "avg / total     0.6686    0.6557    0.6407       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.4193\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2667    0.4211        15\n",
      "      FAVOR     0.6532    0.7642    0.7043       212\n",
      "       NONE     0.6364    0.5417    0.5852       168\n",
      "\n",
      "avg / total     0.6592    0.6506    0.6429       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5627\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.5000    0.2000    0.2857        15\n",
      "      FAVOR     0.6694    0.7736    0.7177       212\n",
      "       NONE     0.6667    0.5714    0.6154       168\n",
      "\n",
      "avg / total     0.6618    0.6658    0.6578       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5017\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.6667    0.2667    0.3810        15\n",
      "      FAVOR     0.6708    0.7594    0.7124       212\n",
      "       NONE     0.6577    0.5833    0.6183       168\n",
      "\n",
      "avg / total     0.6651    0.6658    0.6598       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5467\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=10,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.6250    0.3333    0.4348        15\n",
      "      FAVOR     0.6596    0.7311    0.6935       212\n",
      "       NONE     0.6316    0.5714    0.6000       168\n",
      "\n",
      "avg / total     0.6464    0.6481    0.6439       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5641\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.3333    0.0667    0.1111        15\n",
      "      FAVOR     0.6569    0.8491    0.7407       212\n",
      "       NONE     0.7203    0.5060    0.5944       168\n",
      "\n",
      "avg / total     0.6716    0.6734    0.6546       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.4259\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.3333    0.0667    0.1111        15\n",
      "      FAVOR     0.6615    0.8113    0.7288       212\n",
      "       NONE     0.6818    0.5357    0.6000       168\n",
      "\n",
      "avg / total     0.6577    0.6658    0.6506       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.4200\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.6000    0.2000    0.3000        15\n",
      "      FAVOR     0.6654    0.7972    0.7253       212\n",
      "       NONE     0.6691    0.5417    0.5987       168\n",
      "\n",
      "avg / total     0.6645    0.6658    0.6553       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5127\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.6000    0.2000    0.3000        15\n",
      "      FAVOR     0.6708    0.7689    0.7165       212\n",
      "       NONE     0.6531    0.5714    0.6095       168\n",
      "\n",
      "avg / total     0.6606    0.6633    0.6552       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5082\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=10,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.6000    0.2000    0.3000        15\n",
      "      FAVOR     0.6609    0.7264    0.6921       212\n",
      "       NONE     0.6178    0.5774    0.5969       168\n",
      "\n",
      "avg / total     0.6403    0.6430    0.6367       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.4961\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.3333    0.0667    0.1111        15\n",
      "      FAVOR     0.6582    0.8538    0.7433       212\n",
      "       NONE     0.7265    0.5060    0.5965       168\n",
      "\n",
      "avg / total     0.6749    0.6759    0.6569       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.4272\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.5000    0.1333    0.2105        15\n",
      "      FAVOR     0.6745    0.8113    0.7366       212\n",
      "       NONE     0.6912    0.5595    0.6184       168\n",
      "\n",
      "avg / total     0.6750    0.6785    0.6664       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.4736\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.5000    0.2000    0.2857        15\n",
      "      FAVOR     0.6719    0.8019    0.7312       212\n",
      "       NONE     0.6838    0.5536    0.6118       168\n",
      "\n",
      "avg / total     0.6705    0.6734    0.6635       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5084\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.5000    0.2667    0.3478        15\n",
      "      FAVOR     0.6736    0.7689    0.7181       212\n",
      "       NONE     0.6552    0.5655    0.6070       168\n",
      "\n",
      "avg / total     0.6591    0.6633    0.6568       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5329\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=10,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.5556    0.3333    0.4167        15\n",
      "      FAVOR     0.6824    0.7500    0.7146       212\n",
      "       NONE     0.6471    0.5893    0.6168       168\n",
      "\n",
      "avg / total     0.6626    0.6658    0.6617       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5656\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(3, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6827    0.8726    0.7660       212\n",
      "       NONE     0.7686    0.5536    0.6436       168\n",
      "\n",
      "avg / total     0.7313    0.7114    0.6975       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5497\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(3, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.7073    0.8208    0.7598       212\n",
      "       NONE     0.7329    0.6369    0.6815       168\n",
      "\n",
      "avg / total     0.7293    0.7190    0.7103       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5466\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(3, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.7045    0.8208    0.7582       212\n",
      "       NONE     0.7310    0.6310    0.6773       168\n",
      "\n",
      "avg / total     0.7270    0.7165    0.7076       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5458\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(3, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.7217    0.7830    0.7511       212\n",
      "       NONE     0.7099    0.6845    0.6970       168\n",
      "\n",
      "avg / total     0.7273    0.7190    0.7122       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5422\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=10,\n",
      "        ngram_range=(3, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.5556    0.3333    0.4167        15\n",
      "      FAVOR     0.7051    0.7217    0.7133       212\n",
      "       NONE     0.6509    0.6548    0.6528       168\n",
      "\n",
      "avg / total     0.6763    0.6785    0.6763       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5650\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(3, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.7026    0.8915    0.7859       212\n",
      "       NONE     0.8049    0.5893    0.6804       168\n",
      "\n",
      "avg / total     0.7574    0.7367    0.7238       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5596\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(3, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.7097    0.8302    0.7652       212\n",
      "       NONE     0.7431    0.6369    0.6859       168\n",
      "\n",
      "avg / total     0.7349    0.7241    0.7151       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5493\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(3, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.7149    0.8160    0.7621       212\n",
      "       NONE     0.7333    0.6548    0.6918       168\n",
      "\n",
      "avg / total     0.7336    0.7241    0.7159       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5477\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(3, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.8000    0.2667    0.4000        15\n",
      "      FAVOR     0.7380    0.7972    0.7664       212\n",
      "       NONE     0.7329    0.7024    0.7173       168\n",
      "\n",
      "avg / total     0.7382    0.7367    0.7316       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5832\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=10,\n",
      "        ngram_range=(3, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.4545    0.3333    0.3846        15\n",
      "      FAVOR     0.7230    0.7264    0.7247       212\n",
      "       NONE     0.6725    0.6845    0.6785       168\n",
      "\n",
      "avg / total     0.6913    0.6937    0.6921       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5547\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(3, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6835    0.8962    0.7755       212\n",
      "       NONE     0.7895    0.5357    0.6383       168\n",
      "\n",
      "avg / total     0.7406    0.7165    0.7004       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5544\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(3, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.7500    0.2000    0.3158        15\n",
      "      FAVOR     0.6951    0.8066    0.7467       212\n",
      "       NONE     0.7103    0.6131    0.6581       168\n",
      "\n",
      "avg / total     0.7037    0.7013    0.6927       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5313\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(3, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.7500    0.2000    0.3158        15\n",
      "      FAVOR     0.7029    0.7925    0.7450       212\n",
      "       NONE     0.7039    0.6369    0.6687       168\n",
      "\n",
      "avg / total     0.7051    0.7038    0.6963       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5304\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(3, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.7500    0.2000    0.3158        15\n",
      "      FAVOR     0.7257    0.7736    0.7489       212\n",
      "       NONE     0.7030    0.6905    0.6967       168\n",
      "\n",
      "avg / total     0.7170    0.7165    0.7102       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5323\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=10,\n",
      "        ngram_range=(3, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.3333    0.2000    0.2500        15\n",
      "      FAVOR     0.7053    0.6887    0.6969       212\n",
      "       NONE     0.6480    0.6905    0.6686       168\n",
      "\n",
      "avg / total     0.6668    0.6709    0.6679       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.4734\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(3, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6923    0.8915    0.7794       212\n",
      "       NONE     0.7899    0.5595    0.6551       168\n",
      "\n",
      "avg / total     0.7455    0.7241    0.7096       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5564\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(3, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.8000    0.2667    0.4000        15\n",
      "      FAVOR     0.7033    0.8160    0.7555       212\n",
      "       NONE     0.7222    0.6190    0.6667       168\n",
      "\n",
      "avg / total     0.7150    0.7114    0.7042       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5777\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(3, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.8000    0.2667    0.4000        15\n",
      "      FAVOR     0.7198    0.7877    0.7523       212\n",
      "       NONE     0.7089    0.6667    0.6871       168\n",
      "\n",
      "avg / total     0.7182    0.7165    0.7112       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5761\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(3, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.7143    0.3333    0.4545        15\n",
      "      FAVOR     0.7269    0.7783    0.7517       212\n",
      "       NONE     0.7081    0.6786    0.6930       168\n",
      "\n",
      "avg / total     0.7184    0.7190    0.7155       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.6031\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=10,\n",
      "        ngram_range=(3, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.3846    0.3333    0.3571        15\n",
      "      FAVOR     0.7400    0.6981    0.7184       212\n",
      "       NONE     0.6758    0.7321    0.7029       168\n",
      "\n",
      "avg / total     0.6992    0.6987    0.6981       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5378\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(2, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.0667    0.1250        15\n",
      "      FAVOR     0.6704    0.8538    0.7510       212\n",
      "       NONE     0.7419    0.5476    0.6301       168\n",
      "\n",
      "avg / total     0.7133    0.6937    0.6758       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.4380\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(2, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6911    0.8019    0.7424       212\n",
      "       NONE     0.7055    0.6131    0.6561       168\n",
      "\n",
      "avg / total     0.7089    0.6987    0.6901       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5378\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(2, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.7185    0.8066    0.7600       212\n",
      "       NONE     0.7273    0.6667    0.6957       168\n",
      "\n",
      "avg / total     0.7329    0.7241    0.7164       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5467\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(2, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.7198    0.7877    0.7523       212\n",
      "       NONE     0.7125    0.6786    0.6951       168\n",
      "\n",
      "avg / total     0.7274    0.7190    0.7120       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5428\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=10,\n",
      "        ngram_range=(2, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.6667    0.2667    0.3810        15\n",
      "      FAVOR     0.6858    0.7311    0.7078       212\n",
      "       NONE     0.6503    0.6310    0.6405       168\n",
      "\n",
      "avg / total     0.6700    0.6709    0.6667       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5444\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(2, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.0667    0.1250        15\n",
      "      FAVOR     0.6691    0.8491    0.7484       212\n",
      "       NONE     0.7360    0.5476    0.6280       168\n",
      "\n",
      "avg / total     0.7101    0.6911    0.6735       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.4367\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(2, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6883    0.8019    0.7407       212\n",
      "       NONE     0.7034    0.6071    0.6518       168\n",
      "\n",
      "avg / total     0.7066    0.6962    0.6874       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5370\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(2, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.7045    0.8208    0.7582       212\n",
      "       NONE     0.7310    0.6310    0.6773       168\n",
      "\n",
      "avg / total     0.7270    0.7165    0.7076       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5458\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(2, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2667    0.4211        15\n",
      "      FAVOR     0.7222    0.7972    0.7578       212\n",
      "       NONE     0.7197    0.6726    0.6954       168\n",
      "\n",
      "avg / total     0.7317    0.7241    0.7185       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5895\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=10,\n",
      "        ngram_range=(2, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.5556    0.3333    0.4167        15\n",
      "      FAVOR     0.7054    0.7453    0.7248       212\n",
      "       NONE     0.6728    0.6488    0.6606       168\n",
      "\n",
      "avg / total     0.6858    0.6886    0.6858       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5707\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(2, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.0667    0.1250        15\n",
      "      FAVOR     0.6678    0.9009    0.7671       212\n",
      "       NONE     0.7963    0.5119    0.6232       168\n",
      "\n",
      "avg / total     0.7351    0.7038    0.6815       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.4460\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(2, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.7092    0.8396    0.7689       212\n",
      "       NONE     0.7376    0.6190    0.6731       168\n",
      "\n",
      "avg / total     0.7323    0.7215    0.7116       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5511\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(2, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.7049    0.8113    0.7544       212\n",
      "       NONE     0.7162    0.6310    0.6709       168\n",
      "\n",
      "avg / total     0.7209    0.7114    0.7029       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5439\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(2, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.7500    0.2000    0.3158        15\n",
      "      FAVOR     0.7244    0.7689    0.7460       212\n",
      "       NONE     0.6928    0.6845    0.6886       168\n",
      "\n",
      "avg / total     0.7119    0.7114    0.7053       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5309\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=10,\n",
      "        ngram_range=(2, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.5000    0.2000    0.2857        15\n",
      "      FAVOR     0.7037    0.7170    0.7103       212\n",
      "       NONE     0.6474    0.6667    0.6569       168\n",
      "\n",
      "avg / total     0.6720    0.6759    0.6715       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.4980\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(2, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.0667    0.1250        15\n",
      "      FAVOR     0.6596    0.8868    0.7565       212\n",
      "       NONE     0.7706    0.5000    0.6065       168\n",
      "\n",
      "avg / total     0.7198    0.6911    0.6687       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.4408\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(2, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2667    0.4211        15\n",
      "      FAVOR     0.7020    0.8443    0.7666       212\n",
      "       NONE     0.7353    0.5952    0.6579       168\n",
      "\n",
      "avg / total     0.7275    0.7165    0.7072       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5938\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(2, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.8000    0.2667    0.4000        15\n",
      "      FAVOR     0.7107    0.8113    0.7577       212\n",
      "       NONE     0.7162    0.6310    0.6709       168\n",
      "\n",
      "avg / total     0.7165    0.7139    0.7072       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5789\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(2, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.6667    0.2667    0.3810        15\n",
      "      FAVOR     0.7313    0.7830    0.7563       212\n",
      "       NONE     0.7037    0.6786    0.6909       168\n",
      "\n",
      "avg / total     0.7171    0.7190    0.7142       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5686\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=10,\n",
      "        ngram_range=(2, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.5556    0.3333    0.4167        15\n",
      "      FAVOR     0.7110    0.7311    0.7209       212\n",
      "       NONE     0.6548    0.6548    0.6548       168\n",
      "\n",
      "avg / total     0.6812    0.6835    0.6812       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5688\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(2, 4), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6609    0.9009    0.7625       212\n",
      "       NONE     0.7961    0.4881    0.6052       168\n",
      "\n",
      "avg / total     0.7313    0.6987    0.6793       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5479\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(2, 4), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.7012    0.8302    0.7603       212\n",
      "       NONE     0.7376    0.6190    0.6731       168\n",
      "\n",
      "avg / total     0.7280    0.7165    0.7070       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5468\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(2, 4), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.7160    0.8208    0.7648       212\n",
      "       NONE     0.7383    0.6548    0.6940       168\n",
      "\n",
      "avg / total     0.7363    0.7266    0.7183       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5491\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(2, 4), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.7313    0.7830    0.7563       212\n",
      "       NONE     0.7152    0.7024    0.7087       168\n",
      "\n",
      "avg / total     0.7346    0.7266    0.7200       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5448\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=10,\n",
      "        ngram_range=(2, 4), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.5000    0.2667    0.3478        15\n",
      "      FAVOR     0.7192    0.6887    0.7036       212\n",
      "       NONE     0.6522    0.7143    0.6818       168\n",
      "\n",
      "avg / total     0.6824    0.6835    0.6808       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5257\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(2, 4), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.0667    0.1250        15\n",
      "      FAVOR     0.6553    0.9057    0.7604       212\n",
      "       NONE     0.8020    0.4821    0.6022       168\n",
      "\n",
      "avg / total     0.7308    0.6937    0.6690       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.4427\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(2, 4), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.0667    0.1250        15\n",
      "      FAVOR     0.6899    0.8396    0.7574       212\n",
      "       NONE     0.7426    0.6012    0.6645       168\n",
      "\n",
      "avg / total     0.7241    0.7089    0.6939       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.4412\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(2, 4), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.7178    0.8160    0.7638       212\n",
      "       NONE     0.7351    0.6607    0.6959       168\n",
      "\n",
      "avg / total     0.7359    0.7266    0.7186       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5486\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(2, 4), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.8000    0.2667    0.4000        15\n",
      "      FAVOR     0.7328    0.8019    0.7658       212\n",
      "       NONE     0.7342    0.6905    0.7117       168\n",
      "\n",
      "avg / total     0.7359    0.7342    0.7289       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5829\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=10,\n",
      "        ngram_range=(2, 4), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.5556    0.3333    0.4167        15\n",
      "      FAVOR     0.7513    0.6981    0.7237       212\n",
      "       NONE     0.6667    0.7500    0.7059       168\n",
      "\n",
      "avg / total     0.7079    0.7063    0.7045       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5702\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(2, 4), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6610    0.9198    0.7692       212\n",
      "       NONE     0.8144    0.4702    0.5962       168\n",
      "\n",
      "avg / total     0.7391    0.7013    0.6791       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5513\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(2, 4), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6988    0.8208    0.7549       212\n",
      "       NONE     0.7203    0.6131    0.6624       168\n",
      "\n",
      "avg / total     0.7194    0.7089    0.6995       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5441\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(2, 4), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.7149    0.8160    0.7621       212\n",
      "       NONE     0.7267    0.6488    0.6855       168\n",
      "\n",
      "avg / total     0.7307    0.7215    0.7133       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5477\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(2, 4), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.7376    0.7689    0.7529       212\n",
      "       NONE     0.6959    0.7083    0.7021       168\n",
      "\n",
      "avg / total     0.7298    0.7215    0.7153       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5431\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=10,\n",
      "        ngram_range=(2, 4), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.4286    0.2000    0.2727        15\n",
      "      FAVOR     0.7360    0.6840    0.7090       212\n",
      "       NONE     0.6440    0.7321    0.6852       168\n",
      "\n",
      "avg / total     0.6852    0.6861    0.6824       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.4909\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(2, 4), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.0667    0.1250        15\n",
      "      FAVOR     0.6622    0.9340    0.7750       212\n",
      "       NONE     0.8421    0.4762    0.6084       168\n",
      "\n",
      "avg / total     0.7515    0.7063    0.6794       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.4500\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(2, 4), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.1333    0.2353        15\n",
      "      FAVOR     0.6944    0.8255    0.7543       212\n",
      "       NONE     0.7234    0.6071    0.6602       168\n",
      "\n",
      "avg / total     0.7184    0.7063    0.6946       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.4948\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(2, 4), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2667    0.4211        15\n",
      "      FAVOR     0.7319    0.8113    0.7696       212\n",
      "       NONE     0.7308    0.6786    0.7037       168\n",
      "\n",
      "avg / total     0.7416    0.7342    0.7283       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5953\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(2, 4), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.8000    0.2667    0.4000        15\n",
      "      FAVOR     0.7444    0.7830    0.7632       212\n",
      "       NONE     0.7126    0.7083    0.7104       168\n",
      "\n",
      "avg / total     0.7330    0.7316    0.7270       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5816\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=10,\n",
      "        ngram_range=(2, 4), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.5000    0.3333    0.4000        15\n",
      "      FAVOR     0.7487    0.6887    0.7174       212\n",
      "       NONE     0.6526    0.7381    0.6927       168\n",
      "\n",
      "avg / total     0.6984    0.6962    0.6949       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5587\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(2, 5), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6587    0.9104    0.7644       212\n",
      "       NONE     0.8081    0.4762    0.5993       168\n",
      "\n",
      "avg / total     0.7352    0.6987    0.6778       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5488\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(2, 5), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6902    0.8302    0.7537       212\n",
      "       NONE     0.7299    0.5952    0.6557       168\n",
      "\n",
      "avg / total     0.7189    0.7063    0.6961       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5435\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(2, 5), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.7257    0.8113    0.7661       212\n",
      "       NONE     0.7355    0.6786    0.7059       168\n",
      "\n",
      "avg / total     0.7403    0.7316    0.7241       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5497\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(2, 5), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.7431    0.7642    0.7535       212\n",
      "       NONE     0.7011    0.7262    0.7135       168\n",
      "\n",
      "avg / total     0.7350    0.7266    0.7205       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5434\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=10,\n",
      "        ngram_range=(2, 5), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.4444    0.2667    0.3333        15\n",
      "      FAVOR     0.7527    0.6604    0.7035       212\n",
      "       NONE     0.6500    0.7738    0.7065       168\n",
      "\n",
      "avg / total     0.6973    0.6937    0.6907       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5184\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(2, 5), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6633    0.9292    0.7741       212\n",
      "       NONE     0.8421    0.4762    0.6084       168\n",
      "\n",
      "avg / total     0.7521    0.7089    0.6869       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5537\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(2, 5), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.0667    0.1250        15\n",
      "      FAVOR     0.6962    0.8538    0.7669       212\n",
      "       NONE     0.7612    0.6071    0.6755       168\n",
      "\n",
      "avg / total     0.7354    0.7190    0.7037       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.4460\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(2, 5), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.0667    0.1250        15\n",
      "      FAVOR     0.7185    0.8066    0.7600       212\n",
      "       NONE     0.7308    0.6786    0.7037       168\n",
      "\n",
      "avg / total     0.7344    0.7241    0.7119       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.4425\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(2, 5), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.8000    0.2667    0.4000        15\n",
      "      FAVOR     0.7523    0.7736    0.7628       212\n",
      "       NONE     0.7151    0.7321    0.7235       168\n",
      "\n",
      "avg / total     0.7383    0.7367    0.7323       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5814\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=10,\n",
      "        ngram_range=(2, 5), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.5000    0.3333    0.4000        15\n",
      "      FAVOR     0.7527    0.6604    0.7035       212\n",
      "       NONE     0.6482    0.7679    0.7030       168\n",
      "\n",
      "avg / total     0.6987    0.6937    0.6918       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5518\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(2, 5), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6622    0.9340    0.7750       212\n",
      "       NONE     0.8495    0.4702    0.6054       168\n",
      "\n",
      "avg / total     0.7547    0.7089    0.6861       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5541\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(2, 5), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.7073    0.8208    0.7598       212\n",
      "       NONE     0.7192    0.6250    0.6688       168\n",
      "\n",
      "avg / total     0.7235    0.7139    0.7049       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5466\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(2, 5), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.7308    0.8066    0.7668       212\n",
      "       NONE     0.7215    0.6786    0.6994       168\n",
      "\n",
      "avg / total     0.7371    0.7291    0.7217       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5501\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(2, 5), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.7371    0.7406    0.7388       212\n",
      "       NONE     0.6760    0.7202    0.6974       168\n",
      "\n",
      "avg / total     0.7211    0.7114    0.7058       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5361\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=10,\n",
      "        ngram_range=(2, 5), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.4286    0.2000    0.2727        15\n",
      "      FAVOR     0.7614    0.6321    0.6907       212\n",
      "       NONE     0.6274    0.7917    0.7000       168\n",
      "\n",
      "avg / total     0.6917    0.6835    0.6788       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.4817\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(2, 5), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6667    0.9340    0.7780       212\n",
      "       NONE     0.8421    0.4762    0.6084       168\n",
      "\n",
      "avg / total     0.7539    0.7114    0.6890       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5557\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(2, 5), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.1333    0.2353        15\n",
      "      FAVOR     0.7049    0.8113    0.7544       212\n",
      "       NONE     0.7114    0.6310    0.6688       168\n",
      "\n",
      "avg / total     0.7189    0.7089    0.6983       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.4948\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(2, 5), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2667    0.4211        15\n",
      "      FAVOR     0.7284    0.7972    0.7613       212\n",
      "       NONE     0.7107    0.6726    0.6911       168\n",
      "\n",
      "avg / total     0.7312    0.7241    0.7185       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5912\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(2, 5), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2667    0.4211        15\n",
      "      FAVOR     0.7429    0.7358    0.7393       212\n",
      "       NONE     0.6740    0.7262    0.6991       168\n",
      "\n",
      "avg / total     0.7234    0.7139    0.7102       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5802\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=10,\n",
      "        ngram_range=(2, 5), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.4167    0.3333    0.3704        15\n",
      "      FAVOR     0.7616    0.6179    0.6823       212\n",
      "       NONE     0.6256    0.7857    0.6966       168\n",
      "\n",
      "avg / total     0.6907    0.6785    0.6765       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5263\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.0667    0.1250        15\n",
      "      FAVOR     0.6512    0.7925    0.7149       212\n",
      "       NONE     0.6544    0.5298    0.5855       168\n",
      "\n",
      "avg / total     0.6658    0.6532    0.6375       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.4199\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6545    0.7594    0.7031       212\n",
      "       NONE     0.6370    0.5536    0.5924       168\n",
      "\n",
      "avg / total     0.6602    0.6506    0.6419       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5182\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6598    0.7594    0.7061       212\n",
      "       NONE     0.6486    0.5714    0.6076       168\n",
      "\n",
      "avg / total     0.6680    0.6582    0.6501       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5197\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6681    0.7500    0.7067       212\n",
      "       NONE     0.6429    0.5893    0.6149       168\n",
      "\n",
      "avg / total     0.6700    0.6608    0.6535       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5200\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=10,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2667    0.4211        15\n",
      "      FAVOR     0.6594    0.7123    0.6848       212\n",
      "       NONE     0.6111    0.5893    0.6000       168\n",
      "\n",
      "avg / total     0.6518    0.6430    0.6387       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5529\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.0667    0.1250        15\n",
      "      FAVOR     0.6549    0.7877    0.7152       212\n",
      "       NONE     0.6619    0.5476    0.5993       168\n",
      "\n",
      "avg / total     0.6710    0.6582    0.6435       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.4201\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2667    0.4211        15\n",
      "      FAVOR     0.6545    0.7594    0.7031       212\n",
      "       NONE     0.6345    0.5476    0.5879       168\n",
      "\n",
      "avg / total     0.6591    0.6506    0.6434       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5621\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.6000    0.2000    0.3000        15\n",
      "      FAVOR     0.6736    0.7689    0.7181       212\n",
      "       NONE     0.6689    0.5893    0.6266       168\n",
      "\n",
      "avg / total     0.6688    0.6709    0.6633       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5090\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.8000    0.2667    0.4000        15\n",
      "      FAVOR     0.6722    0.7642    0.7152       212\n",
      "       NONE     0.6644    0.5893    0.6246       168\n",
      "\n",
      "avg / total     0.6737    0.6709    0.6647       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5576\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=10,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.7143    0.3333    0.4545        15\n",
      "      FAVOR     0.6695    0.7358    0.7011       212\n",
      "       NONE     0.6452    0.5952    0.6192       168\n",
      "\n",
      "avg / total     0.6609    0.6608    0.6569       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5778\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.5000    0.0667    0.1176        15\n",
      "      FAVOR     0.6643    0.8679    0.7526       212\n",
      "       NONE     0.7500    0.5179    0.6127       168\n",
      "\n",
      "avg / total     0.6945    0.6886    0.6690       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.4351\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.5000    0.1333    0.2105        15\n",
      "      FAVOR     0.6615    0.8113    0.7288       212\n",
      "       NONE     0.6794    0.5298    0.5953       168\n",
      "\n",
      "avg / total     0.6630    0.6658    0.6524       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.4697\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.6000    0.2000    0.3000        15\n",
      "      FAVOR     0.6707    0.7783    0.7205       212\n",
      "       NONE     0.6597    0.5655    0.6090       168\n",
      "\n",
      "avg / total     0.6634    0.6658    0.6571       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5103\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.7500    0.2000    0.3158        15\n",
      "      FAVOR     0.6597    0.7406    0.6978       212\n",
      "       NONE     0.6275    0.5714    0.5981       168\n",
      "\n",
      "avg / total     0.6494    0.6481    0.6409       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5068\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=10,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6581    0.7264    0.6906       212\n",
      "       NONE     0.6139    0.5774    0.5951       168\n",
      "\n",
      "avg / total     0.6523    0.6430    0.6364       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5120\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.3333    0.0667    0.1111        15\n",
      "      FAVOR     0.6642    0.8491    0.7453       212\n",
      "       NONE     0.7273    0.5238    0.6090       168\n",
      "\n",
      "avg / total     0.6785    0.6810    0.6633       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.4282\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.6000    0.2000    0.3000        15\n",
      "      FAVOR     0.6732    0.8160    0.7377       212\n",
      "       NONE     0.6992    0.5536    0.6179       168\n",
      "\n",
      "avg / total     0.6815    0.6810    0.6702       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5189\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.5714    0.2667    0.3636        15\n",
      "      FAVOR     0.6800    0.8019    0.7359       212\n",
      "       NONE     0.6884    0.5655    0.6209       168\n",
      "\n",
      "avg / total     0.6795    0.6810    0.6729       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5498\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.6667    0.2667    0.3810        15\n",
      "      FAVOR     0.6898    0.7972    0.7396       212\n",
      "       NONE     0.6875    0.5893    0.6346       168\n",
      "\n",
      "avg / total     0.6879    0.6886    0.6813       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5603\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=10,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.5000    0.2667    0.3478        15\n",
      "      FAVOR     0.6826    0.7406    0.7104       212\n",
      "       NONE     0.6433    0.6012    0.6215       168\n",
      "\n",
      "avg / total     0.6590    0.6633    0.6588       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5291\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(3, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6778    0.8632    0.7593       212\n",
      "       NONE     0.7541    0.5476    0.6345       168\n",
      "\n",
      "avg / total     0.7225    0.7038    0.6901       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5463\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(3, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.7028    0.8255    0.7592       212\n",
      "       NONE     0.7273    0.6190    0.6688       168\n",
      "\n",
      "avg / total     0.7245    0.7139    0.7046       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5463\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(3, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.7143    0.8019    0.7556       212\n",
      "       NONE     0.7143    0.6548    0.6832       168\n",
      "\n",
      "avg / total     0.7251    0.7165    0.7088       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5444\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(3, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.7345    0.7830    0.7580       212\n",
      "       NONE     0.7108    0.7024    0.7066       168\n",
      "\n",
      "avg / total     0.7345    0.7266    0.7200       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5457\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=10,\n",
      "        ngram_range=(3, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.4444    0.2667    0.3333        15\n",
      "      FAVOR     0.7062    0.7028    0.7045       212\n",
      "       NONE     0.6514    0.6786    0.6647       168\n",
      "\n",
      "avg / total     0.6729    0.6759    0.6735       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5189\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(3, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6900    0.8821    0.7743       212\n",
      "       NONE     0.7851    0.5655    0.6574       168\n",
      "\n",
      "avg / total     0.7422    0.7215    0.7079       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5538\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(3, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6976    0.8160    0.7522       212\n",
      "       NONE     0.7222    0.6190    0.6667       168\n",
      "\n",
      "avg / total     0.7195    0.7089    0.6999       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5428\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(3, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.7155    0.8066    0.7583       212\n",
      "       NONE     0.7190    0.6548    0.6854       168\n",
      "\n",
      "avg / total     0.7278    0.7190    0.7111       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5458\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(3, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.6667    0.2667    0.3810        15\n",
      "      FAVOR     0.7422    0.7877    0.7643       212\n",
      "       NONE     0.7317    0.7143    0.7229       168\n",
      "\n",
      "avg / total     0.7349    0.7367    0.7321       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5726\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=10,\n",
      "        ngram_range=(3, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.3846    0.3333    0.3571        15\n",
      "      FAVOR     0.7170    0.7170    0.7170       212\n",
      "       NONE     0.6765    0.6845    0.6805       168\n",
      "\n",
      "avg / total     0.6871    0.6886    0.6878       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5371\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(3, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6875    0.8821    0.7727       212\n",
      "       NONE     0.7750    0.5536    0.6458       168\n",
      "\n",
      "avg / total     0.7366    0.7165    0.7021       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5530\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(3, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6895    0.8066    0.7435       212\n",
      "       NONE     0.7014    0.6012    0.6474       168\n",
      "\n",
      "avg / total     0.7064    0.6962    0.6871       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5384\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(3, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.7500    0.2000    0.3158        15\n",
      "      FAVOR     0.7021    0.7783    0.7383       212\n",
      "       NONE     0.6923    0.6429    0.6667       168\n",
      "\n",
      "avg / total     0.6998    0.6987    0.6918       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5270\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(3, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.8000    0.2667    0.4000        15\n",
      "      FAVOR     0.7215    0.7453    0.7332       212\n",
      "       NONE     0.6784    0.6905    0.6844       168\n",
      "\n",
      "avg / total     0.7061    0.7038    0.6998       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5666\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=10,\n",
      "        ngram_range=(3, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.4000    0.2667    0.3200        15\n",
      "      FAVOR     0.7400    0.6981    0.7184       212\n",
      "       NONE     0.6703    0.7381    0.7025       168\n",
      "\n",
      "avg / total     0.6974    0.6987    0.6966       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5192\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(3, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6895    0.9009    0.7812       212\n",
      "       NONE     0.8087    0.5536    0.6572       168\n",
      "\n",
      "avg / total     0.7520    0.7266    0.7115       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5573\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(3, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.8000    0.2667    0.4000        15\n",
      "      FAVOR     0.6840    0.8066    0.7403       212\n",
      "       NONE     0.7000    0.5833    0.6364       168\n",
      "\n",
      "avg / total     0.6952    0.6911    0.6831       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5701\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(3, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.8000    0.2667    0.4000        15\n",
      "      FAVOR     0.7094    0.7830    0.7444       212\n",
      "       NONE     0.6987    0.6488    0.6728       168\n",
      "\n",
      "avg / total     0.7083    0.7063    0.7009       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5722\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(3, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.7143    0.3333    0.4545        15\n",
      "      FAVOR     0.7281    0.7453    0.7366       212\n",
      "       NONE     0.6784    0.6905    0.6844       168\n",
      "\n",
      "avg / total     0.7064    0.7063    0.7037       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5956\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=10,\n",
      "        ngram_range=(3, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.4167    0.3333    0.3704        15\n",
      "      FAVOR     0.7551    0.6981    0.7255       212\n",
      "       NONE     0.6791    0.7560    0.7155       168\n",
      "\n",
      "avg / total     0.7099    0.7089    0.7078       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5479\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(2, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.0667    0.1250        15\n",
      "      FAVOR     0.6778    0.8632    0.7593       212\n",
      "       NONE     0.7581    0.5595    0.6438       168\n",
      "\n",
      "avg / total     0.7242    0.7038    0.6861       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.4422\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(2, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6844    0.7877    0.7325       212\n",
      "       NONE     0.6892    0.6071    0.6456       168\n",
      "\n",
      "avg / total     0.6984    0.6886    0.6803       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5329\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(2, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6987    0.7877    0.7406       212\n",
      "       NONE     0.6993    0.6369    0.6667       168\n",
      "\n",
      "avg / total     0.7104    0.7013    0.6937       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5370\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(2, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.7354    0.7736    0.7540       212\n",
      "       NONE     0.7101    0.7143    0.7122       168\n",
      "\n",
      "avg / total     0.7347    0.7266    0.7202       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5437\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=10,\n",
      "        ngram_range=(2, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.8000    0.2667    0.4000        15\n",
      "      FAVOR     0.7032    0.7264    0.7146       212\n",
      "       NONE     0.6550    0.6667    0.6608       168\n",
      "\n",
      "avg / total     0.6864    0.6835    0.6798       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5573\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(2, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.0667    0.1250        15\n",
      "      FAVOR     0.6754    0.8538    0.7542       212\n",
      "       NONE     0.7460    0.5595    0.6395       168\n",
      "\n",
      "avg / total     0.7178    0.6987    0.6815       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.4396\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(2, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6872    0.7877    0.7341       212\n",
      "       NONE     0.6913    0.6131    0.6498       168\n",
      "\n",
      "avg / total     0.7008    0.6911    0.6830       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5337\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(2, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.7012    0.7972    0.7461       212\n",
      "       NONE     0.7086    0.6369    0.6708       168\n",
      "\n",
      "avg / total     0.7157    0.7063    0.6984       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5397\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(2, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.8000    0.2667    0.4000        15\n",
      "      FAVOR     0.7149    0.7689    0.7409       212\n",
      "       NONE     0.6975    0.6726    0.6848       168\n",
      "\n",
      "avg / total     0.7108    0.7089    0.7041       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5705\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=10,\n",
      "        ngram_range=(2, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.5556    0.3333    0.4167        15\n",
      "      FAVOR     0.7035    0.7500    0.7260       212\n",
      "       NONE     0.6813    0.6488    0.6646       168\n",
      "\n",
      "avg / total     0.6884    0.6911    0.6882       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5713\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(2, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.0667    0.1250        15\n",
      "      FAVOR     0.6678    0.9009    0.7671       212\n",
      "       NONE     0.7963    0.5119    0.6232       168\n",
      "\n",
      "avg / total     0.7351    0.7038    0.6815       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.4460\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(2, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.7040    0.8302    0.7619       212\n",
      "       NONE     0.7254    0.6131    0.6645       168\n",
      "\n",
      "avg / total     0.7243    0.7139    0.7042       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5476\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(2, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.7191    0.7972    0.7562       212\n",
      "       NONE     0.7070    0.6607    0.6831       168\n",
      "\n",
      "avg / total     0.7246    0.7165    0.7090       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5447\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(2, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.7500    0.2000    0.3158        15\n",
      "      FAVOR     0.7188    0.7594    0.7385       212\n",
      "       NONE     0.6826    0.6786    0.6806       168\n",
      "\n",
      "avg / total     0.7046    0.7038    0.6978       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5272\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=10,\n",
      "        ngram_range=(2, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.6000    0.2000    0.3000        15\n",
      "      FAVOR     0.7037    0.7170    0.7103       212\n",
      "       NONE     0.6494    0.6726    0.6608       168\n",
      "\n",
      "avg / total     0.6767    0.6785    0.6737       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5051\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(2, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.0667    0.1250        15\n",
      "      FAVOR     0.6643    0.8962    0.7631       212\n",
      "       NONE     0.7870    0.5060    0.6159       168\n",
      "\n",
      "avg / total     0.7293    0.6987    0.6763       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.4440\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(2, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2667    0.4211        15\n",
      "      FAVOR     0.7020    0.8443    0.7666       212\n",
      "       NONE     0.7353    0.5952    0.6579       168\n",
      "\n",
      "avg / total     0.7275    0.7165    0.7072       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5938\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(2, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.6667    0.2667    0.3810        15\n",
      "      FAVOR     0.7295    0.8396    0.7807       212\n",
      "       NONE     0.7586    0.6548    0.7029       168\n",
      "\n",
      "avg / total     0.7395    0.7392    0.7324       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5808\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(2, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.8000    0.2667    0.4000        15\n",
      "      FAVOR     0.7249    0.7830    0.7528       212\n",
      "       NONE     0.7019    0.6726    0.6869       168\n",
      "\n",
      "avg / total     0.7179    0.7165    0.7114       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5764\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=10,\n",
      "        ngram_range=(2, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.5000    0.3333    0.4000        15\n",
      "      FAVOR     0.7217    0.7217    0.7217       212\n",
      "       NONE     0.6647    0.6845    0.6745       168\n",
      "\n",
      "avg / total     0.6891    0.6911    0.6894       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5608\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(2, 4), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6749    0.9009    0.7717       212\n",
      "       NONE     0.7982    0.5179    0.6282       168\n",
      "\n",
      "avg / total     0.7397    0.7114    0.6940       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5525\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(2, 4), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6932    0.8208    0.7516       212\n",
      "       NONE     0.7234    0.6071    0.6602       168\n",
      "\n",
      "avg / total     0.7177    0.7063    0.6969       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5425\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(2, 4), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.7197    0.8113    0.7627       212\n",
      "       NONE     0.7320    0.6667    0.6978       168\n",
      "\n",
      "avg / total     0.7356    0.7266    0.7188       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5480\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(2, 4), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.7443    0.7689    0.7564       212\n",
      "       NONE     0.7110    0.7321    0.7214       168\n",
      "\n",
      "avg / total     0.7398    0.7316    0.7254       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5449\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=10,\n",
      "        ngram_range=(2, 4), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.5000    0.2667    0.3478        15\n",
      "      FAVOR     0.7353    0.7075    0.7212       212\n",
      "       NONE     0.6721    0.7321    0.7009       168\n",
      "\n",
      "avg / total     0.6995    0.7013    0.6983       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5345\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(2, 4), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.0667    0.1250        15\n",
      "      FAVOR     0.6701    0.9104    0.7720       212\n",
      "       NONE     0.8113    0.5119    0.6277       168\n",
      "\n",
      "avg / total     0.7427    0.7089    0.6861       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.4485\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(2, 4), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.1333    0.2353        15\n",
      "      FAVOR     0.6948    0.8160    0.7505       212\n",
      "       NONE     0.7222    0.6190    0.6667       168\n",
      "\n",
      "avg / total     0.7180    0.7063    0.6953       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.4929\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(2, 4), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.7203    0.8019    0.7589       212\n",
      "       NONE     0.7244    0.6726    0.6975       168\n",
      "\n",
      "avg / total     0.7327    0.7241    0.7167       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5461\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(2, 4), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.6667    0.2667    0.3810        15\n",
      "      FAVOR     0.7376    0.7689    0.7529       212\n",
      "       NONE     0.7143    0.7143    0.7143       168\n",
      "\n",
      "avg / total     0.7250    0.7266    0.7223       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5669\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=10,\n",
      "        ngram_range=(2, 4), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.5000    0.3333    0.4000        15\n",
      "      FAVOR     0.7538    0.6934    0.7224       212\n",
      "       NONE     0.6684    0.7560    0.7095       168\n",
      "\n",
      "avg / total     0.7079    0.7063    0.7046       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5612\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(2, 4), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6701    0.9104    0.7720       212\n",
      "       NONE     0.8077    0.5000    0.6176       168\n",
      "\n",
      "avg / total     0.7412    0.7089    0.6897       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5527\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(2, 4), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6892    0.8160    0.7473       212\n",
      "       NONE     0.7021    0.5893    0.6408       168\n",
      "\n",
      "avg / total     0.7065    0.6962    0.6863       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5403\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(2, 4), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.7234    0.8019    0.7606       212\n",
      "       NONE     0.7134    0.6667    0.6892       168\n",
      "\n",
      "avg / total     0.7296    0.7215    0.7140       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5470\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(2, 4), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.7500    0.2000    0.3158        15\n",
      "      FAVOR     0.7327    0.7500    0.7413       212\n",
      "       NONE     0.6839    0.7083    0.6959       168\n",
      "\n",
      "avg / total     0.7126    0.7114    0.7058       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5285\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=10,\n",
      "        ngram_range=(2, 4), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.5714    0.2667    0.3636        15\n",
      "      FAVOR     0.7460    0.6651    0.7032       212\n",
      "       NONE     0.6432    0.7619    0.6975       168\n",
      "\n",
      "avg / total     0.6957    0.6911    0.6879       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5334\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(2, 4), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.0667    0.1250        15\n",
      "      FAVOR     0.6678    0.9198    0.7738       212\n",
      "       NONE     0.8235    0.5000    0.6222       168\n",
      "\n",
      "avg / total     0.7467    0.7089    0.6847       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.4494\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(2, 4), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.7016    0.8208    0.7565       212\n",
      "       NONE     0.7153    0.6131    0.6603       168\n",
      "\n",
      "avg / total     0.7188    0.7089    0.6995       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5449\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(2, 4), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2667    0.4211        15\n",
      "      FAVOR     0.7446    0.8113    0.7765       212\n",
      "       NONE     0.7312    0.6964    0.7134       168\n",
      "\n",
      "avg / total     0.7486    0.7418    0.7362       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5988\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(2, 4), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.8000    0.2667    0.4000        15\n",
      "      FAVOR     0.7430    0.7500    0.7465       212\n",
      "       NONE     0.6875    0.7202    0.7035       168\n",
      "\n",
      "avg / total     0.7216    0.7190    0.7150       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5732\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=10,\n",
      "        ngram_range=(2, 4), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.5556    0.3333    0.4167        15\n",
      "      FAVOR     0.7527    0.6604    0.7035       212\n",
      "       NONE     0.6400    0.7619    0.6957       168\n",
      "\n",
      "avg / total     0.6973    0.6911    0.6893       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5601\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(2, 5), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6667    0.9151    0.7714       212\n",
      "       NONE     0.8119    0.4881    0.6097       168\n",
      "\n",
      "avg / total     0.7411    0.7063    0.6860       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5524\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(2, 5), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.1333    0.2353        15\n",
      "      FAVOR     0.6976    0.8160    0.7522       212\n",
      "       NONE     0.7241    0.6250    0.6709       168\n",
      "\n",
      "avg / total     0.7204    0.7089    0.6980       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.4937\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(2, 5), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.7265    0.8019    0.7623       212\n",
      "       NONE     0.7278    0.6845    0.7055       168\n",
      "\n",
      "avg / total     0.7375    0.7291    0.7219       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5478\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(2, 5), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.7465    0.7500    0.7482       212\n",
      "       NONE     0.6927    0.7381    0.7147       168\n",
      "\n",
      "avg / total     0.7332    0.7241    0.7182       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5408\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=10,\n",
      "        ngram_range=(2, 5), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.5000    0.2667    0.3478        15\n",
      "      FAVOR     0.7287    0.6462    0.6850       212\n",
      "       NONE     0.6231    0.7381    0.6757       168\n",
      "\n",
      "avg / total     0.6751    0.6709    0.6683       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5164\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(2, 5), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6622    0.9245    0.7717       212\n",
      "       NONE     0.8229    0.4702    0.5985       168\n",
      "\n",
      "avg / total     0.7434    0.7038    0.6814       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5525\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(2, 5), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.0667    0.1250        15\n",
      "      FAVOR     0.7000    0.8255    0.7576       212\n",
      "       NONE     0.7361    0.6310    0.6795       168\n",
      "\n",
      "avg / total     0.7268    0.7139    0.7003       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.4413\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(2, 5), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.7277    0.8066    0.7651       212\n",
      "       NONE     0.7325    0.6845    0.7077       168\n",
      "\n",
      "avg / total     0.7401    0.7316    0.7243       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5492\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(2, 5), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.6667    0.2667    0.3810        15\n",
      "      FAVOR     0.7500    0.7500    0.7500       212\n",
      "       NONE     0.7006    0.7381    0.7188       168\n",
      "\n",
      "avg / total     0.7258    0.7266    0.7227       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5655\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=10,\n",
      "        ngram_range=(2, 5), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.5000    0.3333    0.4000        15\n",
      "      FAVOR     0.7540    0.6651    0.7068       212\n",
      "       NONE     0.6515    0.7679    0.7049       168\n",
      "\n",
      "avg / total     0.7008    0.6962    0.6943       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5534\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(2, 5), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6701    0.9198    0.7753       212\n",
      "       NONE     0.8218    0.4940    0.6171       168\n",
      "\n",
      "avg / total     0.7471    0.7114    0.6913       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5543\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(2, 5), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6825    0.8113    0.7414       212\n",
      "       NONE     0.6929    0.5774    0.6299       168\n",
      "\n",
      "avg / total     0.6990    0.6886    0.6785       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5374\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(2, 5), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.7500    0.2000    0.3158        15\n",
      "      FAVOR     0.7366    0.7783    0.7569       212\n",
      "       NONE     0.7066    0.7024    0.7045       168\n",
      "\n",
      "avg / total     0.7243    0.7241    0.7178       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5363\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(2, 5), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.7500    0.2000    0.3158        15\n",
      "      FAVOR     0.7548    0.7406    0.7476       212\n",
      "       NONE     0.6885    0.7500    0.7179       168\n",
      "\n",
      "avg / total     0.7264    0.7241    0.7186       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5317\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=True, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=10,\n",
      "        ngram_range=(2, 5), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.5714    0.2667    0.3636        15\n",
      "      FAVOR     0.7543    0.6226    0.6822       212\n",
      "       NONE     0.6244    0.7917    0.6982       168\n",
      "\n",
      "avg / total     0.6921    0.6810    0.6769       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5229\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(2, 5), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2000    0.3333        15\n",
      "      FAVOR     0.6655    0.9292    0.7756       212\n",
      "       NONE     0.8333    0.4762    0.6061       168\n",
      "\n",
      "avg / total     0.7496    0.7089    0.6867       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5545\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(2, 5), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.1333    0.2353        15\n",
      "      FAVOR     0.7097    0.8302    0.7652       212\n",
      "       NONE     0.7310    0.6310    0.6773       168\n",
      "\n",
      "avg / total     0.7298    0.7190    0.7077       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5003\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(2, 5), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.2667    0.4211        15\n",
      "      FAVOR     0.7500    0.7925    0.7706       212\n",
      "       NONE     0.7186    0.7143    0.7164       168\n",
      "\n",
      "avg / total     0.7461    0.7392    0.7343       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5958\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(2, 5), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.6667    0.2667    0.3810        15\n",
      "      FAVOR     0.7561    0.7311    0.7434       212\n",
      "       NONE     0.6848    0.7500    0.7159       168\n",
      "\n",
      "avg / total     0.7224    0.7215    0.7179       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5622\n",
      "\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=10,\n",
      "        ngram_range=(2, 5), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.4545    0.3333    0.3846        15\n",
      "      FAVOR     0.7805    0.6038    0.6809       212\n",
      "       NONE     0.6273    0.8214    0.7113       168\n",
      "\n",
      "avg / total     0.7029    0.6861    0.6826       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.5327\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "\n",
    "for analyzer in 'word', 'char', 'char_wb':\n",
    "    if analyzer == 'word':\n",
    "        ngram_ranges = [(1,1), (2,2), (1,2)]\n",
    "        min_dfs = 1,2\n",
    "    else:\n",
    "        ngram_ranges = [(2,2),(3,3),(2,3),(2,4),(2,5)]\n",
    "        min_dfs = 1,2,3,5,10\n",
    "    for ngram_range in ngram_ranges:\n",
    "        for lowercase in True, False:\n",
    "            for binary in True, False:\n",
    "                for min_df in min_dfs:                \n",
    "                    pipeline = Pipeline([('vect', CountVectorizer(decode_error='ignore',\n",
    "                                                                  binary=binary,\n",
    "                                                                  lowercase=lowercase,\n",
    "                                                                  min_df=min_df,\n",
    "                                                                  ngram_range=ngram_range,\n",
    "                                                                  analyzer=analyzer)),\n",
    "                                         ('clf', MultinomialNB())])\n",
    "                    print pipeline\n",
    "\n",
    "                    pred_stances = cross_val_predict(pipeline, target_data.Tweet, target_data.Stance, cv=cv)\n",
    "                    print classification_report(target_data.Stance, pred_stances, digits=4)\n",
    "\n",
    "                    macro_f = fbeta_score(target_data.Stance, pred_stances, 1.0, \n",
    "                                          labels=['AGAINST', 'FAVOR'], average='macro')\n",
    "                    print 'macro-average of F-score(FAVOR) and F-score(AGAINST): {:.4f}\\n'.\\\n",
    "                    format(macro_f)\n",
    "                    results.iloc[i] = (analyzer, str(ngram_range), lowercase, binary, min_df, macro_f)\n",
    "                    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    analyzer ngram_range lowercase binary  min_df   macro_f\n",
      "62      char      (3, 3)     False  False       5  0.603127\n",
      "201  char_wb      (2, 4)     False  False       3  0.598788\n",
      "221  char_wb      (2, 5)     False  False       3  0.595847\n",
      "162  char_wb      (3, 3)     False  False       5  0.595571\n",
      "101     char      (2, 4)     False  False       3  0.595314\n",
      "80      char      (2, 3)     False  False       2  0.593824\n",
      "180  char_wb      (2, 3)     False  False       2  0.593824\n",
      "121     char      (2, 5)     False  False       3  0.591157\n",
      "72      char      (2, 3)      True  False       5  0.589450\n",
      "52      char      (3, 3)      True  False       5  0.583220\n",
      "92      char      (2, 4)      True  False       5  0.582883\n",
      "102     char      (2, 4)     False  False       5  0.581609\n",
      "112     char      (2, 5)      True  False       5  0.581395\n",
      "181  char_wb      (2, 3)     False  False       3  0.580827\n",
      "122     char      (2, 5)     False  False       5  0.580195\n",
      "81      char      (2, 3)     False  False       3  0.578855\n",
      "133  char_wb      (2, 2)      True  False      10  0.577835\n",
      "60      char      (3, 3)     False  False       2  0.577729\n",
      "182  char_wb      (2, 3)     False  False       5  0.576417\n",
      "61      char      (3, 3)     False  False       3  0.576126\n",
      "14      word      (2, 2)     False  False       1  0.575761\n",
      "202  char_wb      (2, 4)     False  False       5  0.573239\n",
      "152  char_wb      (3, 3)      True  False       5  0.572627\n",
      "161  char_wb      (3, 3)     False  False       3  0.572197\n",
      "173  char_wb      (2, 3)      True  False      10  0.571347\n",
      "73      char      (2, 3)      True  False      10  0.570719\n",
      "172  char_wb      (2, 3)      True  False       5  0.570455\n",
      "93      char      (2, 4)      True  False      10  0.570192\n",
      "160  char_wb      (3, 3)     False  False       2  0.570130\n",
      "83      char      (2, 3)     False  False      10  0.568798\n",
      "82      char      (2, 3)     False  False       5  0.568608\n",
      "192  char_wb      (2, 4)      True  False       5  0.566920\n",
      "157  char_wb      (3, 3)     False   True       5  0.566589\n",
      "43      char      (2, 2)     False  False      10  0.565637\n",
      "212  char_wb      (2, 5)      True  False       5  0.565476\n",
      "48      char      (3, 3)      True   True      10  0.564977\n",
      "33      char      (2, 2)      True  False      10  0.564147\n",
      "30      char      (2, 2)      True  False       2  0.562700\n",
      "222  char_wb      (2, 5)     False  False       5  0.562179\n",
      "130  char_wb      (2, 2)      True  False       2  0.562055\n",
      "193  char_wb      (2, 4)      True  False      10  0.561179\n",
      "183  char_wb      (2, 3)     False  False      10  0.560849\n",
      "142  char_wb      (2, 2)     False  False       5  0.560279\n",
      "203  char_wb      (2, 4)     False  False      10  0.560092\n",
      "49      char      (3, 3)      True  False       1  0.559598\n",
      "103     char      (2, 4)     False  False      10  0.558722\n",
      "132  char_wb      (2, 2)      True  False       5  0.557616\n",
      "168  char_wb      (2, 3)      True   True      10  0.557309\n",
      "159  char_wb      (3, 3)     False  False       1  0.557260\n",
      "59      char      (3, 3)     False  False       1  0.556357\n",
      "119     char      (2, 5)     False  False       1  0.555665\n",
      "53      char      (3, 3)      True  False      10  0.554661\n",
      "219  char_wb      (2, 5)     False  False       1  0.554462\n",
      "54      char      (3, 3)     False   True       1  0.554422\n",
      "214  char_wb      (2, 5)     False   True       1  0.554341\n",
      "114     char      (2, 5)     False   True       1  0.554142\n",
      "149  char_wb      (3, 3)      True  False       1  0.553830\n",
      "109     char      (2, 5)      True  False       1  0.553700\n",
      "213  char_wb      (2, 5)      True  False      10  0.553383\n",
      "154  char_wb      (3, 3)     False   True       1  0.553030\n",
      "128  char_wb      (2, 2)      True   True      10  0.552930\n",
      "28      char      (2, 2)      True   True      10  0.552869\n",
      "194  char_wb      (2, 4)     False   True       1  0.552667\n",
      "184  char_wb      (2, 4)      True   True       1  0.552525\n",
      "209  char_wb      (2, 5)      True  False       1  0.552493\n",
      "204  char_wb      (2, 5)      True   True       1  0.552353\n",
      "113     char      (2, 5)      True  False      10  0.551759\n",
      "94      char      (2, 4)     False   True       1  0.551282\n",
      "75      char      (2, 3)     False   True       2  0.551116\n",
      "116     char      (2, 5)     False   True       3  0.550075\n",
      "2       word      (1, 1)      True  False       1  0.550000\n",
      "141  char_wb      (2, 2)     False  False       3  0.549784\n",
      "106     char      (2, 5)      True   True       3  0.549740\n",
      "44      char      (3, 3)      True   True       1  0.549689\n",
      "50      char      (3, 3)      True  False       2  0.549275\n",
      "211  char_wb      (2, 5)      True  False       3  0.549217\n",
      "86      char      (2, 4)      True   True       3  0.549084\n",
      "104     char      (2, 5)      True   True       1  0.548845\n",
      "91      char      (2, 4)      True  False       3  0.548565\n",
      "186  char_wb      (2, 4)      True   True       3  0.548041\n",
      "163  char_wb      (3, 3)     False  False      10  0.547930\n",
      "84      char      (2, 4)      True   True       1  0.547904\n",
      "206  char_wb      (2, 5)      True   True       3  0.547833\n",
      "51      char      (3, 3)      True  False       3  0.547724\n",
      "96      char      (2, 4)     False   True       3  0.547724\n",
      "175  char_wb      (2, 3)     False   True       2  0.547619\n",
      "196  char_wb      (2, 4)     False   True       3  0.546980\n",
      "85      char      (2, 4)      True   True       2  0.546796\n",
      "32      char      (2, 2)      True  False       5  0.546671\n",
      "66      char      (2, 3)      True   True       3  0.546667\n",
      "115     char      (2, 5)     False   True       2  0.546579\n",
      "45      char      (3, 3)      True   True       2  0.546579\n",
      "144  char_wb      (3, 3)      True   True       1  0.546335\n",
      "145  char_wb      (3, 3)      True   True       2  0.546276\n",
      "191  char_wb      (2, 4)      True  False       3  0.546131\n",
      "151  char_wb      (3, 3)      True  False       3  0.545824\n",
      "22      word      (1, 2)     False  False       1  0.545765\n",
      "71      char      (2, 3)      True  False       3  0.545752\n",
      "46      char      (3, 3)      True   True       3  0.545752\n",
      "147  char_wb      (3, 3)      True   True       5  0.545662\n",
      "200  char_wb      (2, 4)     False  False       2  0.544928\n",
      "187  char_wb      (2, 4)      True   True       5  0.544857\n",
      "87      char      (2, 4)      True   True       5  0.544799\n",
      "176  char_wb      (2, 3)     False   True       3  0.544743\n",
      "0       word      (1, 1)      True   True       1  0.544537\n",
      "146  char_wb      (3, 3)      True   True       3  0.544444\n",
      "68      char      (2, 3)      True   True      10  0.544357\n",
      "95      char      (2, 4)     False   True       2  0.544107\n",
      "76      char      (2, 3)     False   True       3  0.543860\n",
      "20      word      (1, 2)     False   True       1  0.543750\n",
      "167  char_wb      (2, 3)      True   True       5  0.543678\n",
      "105     char      (2, 5)      True   True       2  0.543540\n",
      "107     char      (2, 5)      True   True       5  0.543411\n",
      "97      char      (2, 4)     False   True       5  0.543110\n",
      "67      char      (2, 3)      True   True       5  0.542793\n",
      "150  char_wb      (3, 3)      True  False       2  0.542754\n",
      "185  char_wb      (2, 4)      True   True       2  0.542477\n",
      "18      word      (1, 2)      True  False       1  0.542424\n",
      "47      char      (3, 3)      True   True       5  0.542232\n",
      "207  char_wb      (2, 5)      True   True       5  0.540784\n",
      "195  char_wb      (2, 4)     False   True       2  0.540317\n",
      "171  char_wb      (2, 3)      True  False       3  0.539735\n",
      "16      word      (1, 2)      True   True       1  0.539136\n",
      "155  char_wb      (3, 3)     False   True       2  0.538406\n",
      "65      char      (2, 3)      True   True       2  0.537846\n",
      "63      char      (3, 3)     False  False      10  0.537795\n",
      "215  char_wb      (2, 5)     False   True       2  0.537356\n",
      "153  char_wb      (3, 3)      True  False      10  0.537062\n",
      "70      char      (2, 3)      True  False       2  0.537037\n",
      "166  char_wb      (2, 3)      True   True       3  0.536955\n",
      "4       word      (1, 1)     False   True       1  0.536415\n",
      "216  char_wb      (2, 5)     False   True       3  0.536335\n",
      "117     char      (2, 5)     False   True       5  0.536078\n",
      "6       word      (1, 1)     False  False       1  0.534868\n",
      "188  char_wb      (2, 4)      True   True      10  0.534490\n",
      "170  char_wb      (2, 3)      True  False       2  0.533700\n",
      "198  char_wb      (2, 4)     False   True      10  0.533439\n",
      "42      char      (2, 2)     False  False       5  0.532944\n",
      "165  char_wb      (2, 3)      True   True       2  0.532895\n",
      "223  char_wb      (2, 5)     False  False      10  0.532733\n",
      "57      char      (3, 3)     False   True       5  0.532324\n",
      "217  char_wb      (2, 5)     False   True       5  0.531704\n",
      "55      char      (3, 3)     False   True       2  0.531257\n",
      "12      word      (2, 2)     False   True       1  0.531189\n",
      "77      char      (2, 3)     False   True       5  0.530892\n",
      "56      char      (3, 3)     False   True       3  0.530400\n",
      "143  char_wb      (2, 2)     False  False      10  0.529117\n",
      "197  char_wb      (2, 4)     False   True       5  0.528524\n",
      "177  char_wb      (2, 3)     False   True       5  0.527161\n",
      "156  char_wb      (3, 3)     False   True       3  0.527022\n",
      "123     char      (2, 5)     False  False      10  0.526331\n",
      "88      char      (2, 4)      True   True      10  0.525720\n",
      "8       word      (2, 2)      True   True       1  0.524374\n",
      "10      word      (2, 2)      True  False       1  0.522966\n",
      "218  char_wb      (2, 5)     False   True      10  0.522903\n",
      "127  char_wb      (2, 2)      True   True       5  0.520000\n",
      "126  char_wb      (2, 2)      True   True       3  0.519737\n",
      "158  char_wb      (3, 3)     False   True      10  0.519223\n",
      "27      char      (2, 2)      True   True       5  0.519217\n",
      "148  char_wb      (3, 3)      True   True      10  0.518913\n",
      "140  char_wb      (2, 2)     False  False       2  0.518870\n",
      "108     char      (2, 5)      True   True      10  0.518425\n",
      "26      char      (2, 2)      True   True       3  0.518195\n",
      "125  char_wb      (2, 2)      True   True       2  0.518195\n",
      "208  char_wb      (2, 5)      True   True      10  0.516413\n",
      "25      char      (2, 2)      True   True       2  0.514588\n",
      "36      char      (2, 2)     False   True       3  0.512661\n",
      "138  char_wb      (2, 2)     False   True      10  0.511958\n",
      "136  char_wb      (2, 2)     False   True       3  0.510262\n",
      "131  char_wb      (2, 2)      True  False       3  0.509031\n",
      "41      char      (2, 2)     False  False       3  0.508449\n",
      "37      char      (2, 2)     False   True       5  0.508242\n",
      "137  char_wb      (2, 2)     False   True       5  0.506784\n",
      "178  char_wb      (2, 3)     False   True      10  0.505140\n",
      "31      char      (2, 2)      True  False       3  0.501719\n",
      "220  char_wb      (2, 5)     False  False       2  0.500256\n",
      "78      char      (2, 3)     False   True      10  0.497997\n",
      "38      char      (2, 2)     False   True      10  0.496067\n",
      "120     char      (2, 5)     False  False       2  0.494840\n",
      "100     char      (2, 4)     False  False       2  0.494802\n",
      "205  char_wb      (2, 5)      True   True       2  0.493734\n",
      "190  char_wb      (2, 4)      True  False       2  0.492918\n",
      "98      char      (2, 4)     False   True      10  0.490887\n",
      "118     char      (2, 5)     False   True      10  0.481724\n",
      "40      char      (2, 2)     False  False       2  0.473572\n",
      "58      char      (3, 3)     False   True      10  0.473449\n",
      "135  char_wb      (2, 2)     False   True       2  0.469670\n",
      "99      char      (2, 4)     False  False       1  0.449976\n",
      "199  char_wb      (2, 4)     False  False       1  0.449405\n",
      "189  char_wb      (2, 4)      True  False       1  0.448500\n",
      "174  char_wb      (2, 3)     False   True       1  0.446034\n",
      "74      char      (2, 3)     False   True       1  0.446034\n",
      "110     char      (2, 5)      True  False       2  0.445975\n",
      "179  char_wb      (2, 3)     False  False       1  0.444026\n",
      "89      char      (2, 4)      True  False       1  0.442698\n",
      "111     char      (2, 5)      True  False       3  0.442500\n",
      "164  char_wb      (2, 3)      True   True       1  0.442168\n",
      "210  char_wb      (2, 5)      True  False       2  0.441288\n",
      "90      char      (2, 4)      True  False       2  0.441223\n",
      "79      char      (2, 3)     False  False       1  0.440770\n",
      "169  char_wb      (2, 3)      True  False       1  0.439583\n",
      "64      char      (2, 3)      True   True       1  0.438019\n",
      "69      char      (2, 3)      True  False       1  0.436720\n",
      "134  char_wb      (2, 2)     False   True       1  0.435102\n",
      "3       word      (1, 1)      True  False       2  0.434491\n",
      "1       word      (1, 1)      True   True       2  0.432065\n",
      "17      word      (1, 2)      True   True       2  0.431628\n",
      "19      word      (1, 2)      True  False       2  0.428946\n",
      "139  char_wb      (2, 2)     False  False       1  0.428226\n",
      "39      char      (2, 2)     False  False       1  0.427219\n",
      "34      char      (2, 2)     False   True       1  0.425926\n",
      "23      word      (1, 2)     False  False       2  0.422860\n",
      "21      word      (1, 2)     False   True       2  0.420947\n",
      "5       word      (1, 1)     False   True       2  0.420442\n",
      "129  char_wb      (2, 2)      True  False       1  0.420102\n",
      "35      char      (2, 2)     False   True       2  0.419962\n",
      "124  char_wb      (2, 2)      True   True       1  0.419947\n",
      "7       word      (1, 1)     False  False       2  0.419484\n",
      "29      char      (2, 2)      True  False       1  0.419338\n",
      "24      char      (2, 2)      True   True       1  0.419188\n",
      "15      word      (2, 2)     False  False       2  0.396473\n",
      "13      word      (2, 2)     False   True       2  0.395833\n",
      "9       word      (2, 2)      True   True       2  0.393461\n",
      "11      word      (2, 2)      True  False       2  0.391505\n"
     ]
    }
   ],
   "source": [
    "results = results[results.analyzer != '']\n",
    "pd.set_option('display.max_rows', len(results))\n",
    "results.sort_values(by='macro_f', ascending=False, inplace=True)\n",
    "print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   analyzer ngram_range lowercase binary  min_df   macro_f\n",
      "14     word      (2, 2)     False  False       1  0.575761\n",
      "2      word      (1, 1)      True  False       1  0.550000\n",
      "22     word      (1, 2)     False  False       1  0.545765\n",
      "0      word      (1, 1)      True   True       1  0.544537\n",
      "20     word      (1, 2)     False   True       1  0.543750\n",
      "18     word      (1, 2)      True  False       1  0.542424\n",
      "16     word      (1, 2)      True   True       1  0.539136\n",
      "4      word      (1, 1)     False   True       1  0.536415\n",
      "6      word      (1, 1)     False  False       1  0.534868\n",
      "12     word      (2, 2)     False   True       1  0.531189\n",
      "8      word      (2, 2)      True   True       1  0.524374\n",
      "10     word      (2, 2)      True  False       1  0.522966\n",
      "3      word      (1, 1)      True  False       2  0.434491\n",
      "1      word      (1, 1)      True   True       2  0.432065\n",
      "17     word      (1, 2)      True   True       2  0.431628\n",
      "19     word      (1, 2)      True  False       2  0.428946\n",
      "23     word      (1, 2)     False  False       2  0.422860\n",
      "21     word      (1, 2)     False   True       2  0.420947\n",
      "5      word      (1, 1)     False   True       2  0.420442\n",
      "7      word      (1, 1)     False  False       2  0.419484\n",
      "15     word      (2, 2)     False  False       2  0.396473\n",
      "13     word      (2, 2)     False   True       2  0.395833\n",
      "9      word      (2, 2)      True   True       2  0.393461\n",
      "11     word      (2, 2)      True  False       2  0.391505\n"
     ]
    }
   ],
   "source": [
    "print results[results.analyzer == 'word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
