{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run 1 #\n",
    "\n",
    "Submitted as EM@NTNU.\n",
    "\n",
    "Based on Exp14: voting with C-tuned classifiers.\n",
    "\n",
    "Requires Glove vectors from make_all_glove_vecs.py and tuned C values from notebooks exp11 and exp12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Atheism\n",
      "================================================================================\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.9450    0.9046    0.9244       304\n",
      "      FAVOR     0.8144    0.8587    0.8360        92\n",
      "       NONE     0.8800    0.9402    0.9091       117\n",
      "\n",
      "avg / total     0.9068    0.9045    0.9050       513\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.8802\n",
      "\n",
      "================================================================================\n",
      "Climate Change is a Real Concern\n",
      "================================================================================\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.3333    0.5000        15\n",
      "      FAVOR     0.6732    0.9717    0.7954       212\n",
      "       NONE     0.9167    0.4583    0.6111       168\n",
      "\n",
      "avg / total     0.7892    0.7291    0.7058       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.6477\n",
      "\n",
      "================================================================================\n",
      "Feminist Movement\n",
      "================================================================================\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.8235    0.8963    0.8584       328\n",
      "      FAVOR     0.8580    0.7190    0.7824       210\n",
      "       NONE     0.8397    0.8730    0.8560       126\n",
      "\n",
      "avg / total     0.8375    0.8358    0.8339       664\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.8204\n",
      "\n",
      "================================================================================\n",
      "Hillary Clinton\n",
      "================================================================================\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.8963    0.9335    0.9145       361\n",
      "      FAVOR     0.8846    0.8214    0.8519       112\n",
      "       NONE     0.8994    0.8614    0.8800       166\n",
      "\n",
      "avg / total     0.8950    0.8951    0.8946       639\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.8832\n",
      "\n",
      "================================================================================\n",
      "Legalization of Abortion\n",
      "================================================================================\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.9254    0.9281    0.9268       334\n",
      "      FAVOR     0.8462    0.8381    0.8421       105\n",
      "       NONE     0.9085    0.9085    0.9085       164\n",
      "\n",
      "avg / total     0.9070    0.9071    0.9071       603\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.8844\n",
      "\n",
      "================================================================================\n",
      "Overall\n",
      "================================================================================\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.8952    0.9098    0.9024      1342\n",
      "      FAVOR     0.7827    0.8427    0.8116       731\n",
      "       NONE     0.8884    0.7949    0.8390       741\n",
      "\n",
      "avg / total     0.8642    0.8621    0.8621      2814\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.8570\n",
      "\n",
      "Writing  run1_train.txt\n",
      "Writing  run1_test.txt\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from cPickle import load\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import classification_report, fbeta_score\n",
    "\n",
    "from glove_transformer import GloveVectorizer\n",
    "\n",
    "# read training and test data\n",
    "\n",
    "train_data = pd.read_csv(open('semeval2016-task6-trainingdata-utf-8.txt'), '\\t',\n",
    "                         encoding='utf8',\n",
    "                         index_col=0)\n",
    "targets = list(train_data.Target.unique())\n",
    "\n",
    "test_data = pd.read_csv(open('SemEval2016-Task6-subtaskA-testdata.txt'), '\\t',\n",
    "                        encoding='utf8',\n",
    "                        index_col=0)\n",
    "\n",
    "# read Glove vectors\n",
    "\n",
    "glove_fnames = ('glove_vecs/glove.42B.300d_semeval2016-task6.pkl',\n",
    "                'glove_vecs/glove.6B.300d_semeval2016-task6.pkl',\n",
    "                'glove_vecs/glove.840B.300d_semeval2016-task6.pkl',\n",
    "                'glove_vecs/glove.twitter.27B.200d_semeval2016-task6.pkl'\n",
    "                )\n",
    "\n",
    "glove_ids = [fname.split('/')[-1].split('_')[0] for fname in glove_fnames]\n",
    "\n",
    "glove_vecs = dict((id, pd.read_pickle(fname))\n",
    "                  for id, fname in zip(glove_ids, glove_fnames))\n",
    "\n",
    "# read tuned C values\n",
    "\n",
    "C1 = load(open('word_bigram_char_svc_c_tuning.pkl'))\n",
    "C2 = load(open('glove_svc_c_tuning.pkl'))\n",
    "\n",
    "# construct classifiers\n",
    "\n",
    "classifiers = dict(\n",
    "        char_clf=Pipeline([\n",
    "            ('vect', CountVectorizer(decode_error='ignore',\n",
    "                                     lowercase=False,\n",
    "                                     min_df=5,\n",
    "                                     ngram_range=(3, 3),\n",
    "                                     analyzer='char')),\n",
    "            ('clf', LinearSVC(class_weight='balanced'))]),\n",
    "\n",
    "        word_clf=Pipeline([\n",
    "            ('vect', CountVectorizer(decode_error='ignore',\n",
    "                                     lowercase=False,\n",
    "                                     ngram_range=(1, 2))),\n",
    "            ('clf', LinearSVC(class_weight='balanced'))]),\n",
    "\n",
    "        bigram_clf=Pipeline([\n",
    "            ('vect', CountVectorizer(decode_error='ignore',\n",
    "                                     stop_words='english',\n",
    "                                     lowercase=False)),\n",
    "            ('clf', LinearSVC(class_weight='balanced'))])\n",
    ")\n",
    "\n",
    "for id in glove_ids:\n",
    "    glove_clf = GloveVectorizer(glove_vecs[id])\n",
    "    classifiers[id] = Pipeline([('vect', glove_clf),\n",
    "                                ('clf', LinearSVC(class_weight='balanced'))])\n",
    "\n",
    "vot_clf = VotingClassifier(\n",
    "        estimators=classifiers.items())\n",
    "\n",
    "# run\n",
    "\n",
    "true_train_stances = train_data.Stance.copy()\n",
    "\n",
    "for target in targets:\n",
    "    print 80 * \"=\"\n",
    "    print target\n",
    "    print 80 * \"=\"\n",
    "\n",
    "    target_train_data = train_data[train_data.Target == target]\n",
    "    true_stances = target_train_data.Stance\n",
    "\n",
    "    # set C values\n",
    "    for clf_name, clf in vot_clf.named_estimators.items():\n",
    "        if clf_name in glove_ids:\n",
    "            query = \"target == '{}' & glove_id == '{}' \".format(target,\n",
    "                                                                clf_name)\n",
    "            C = float(C2.query(query)['select_C'])\n",
    "            clf.set_params(clf__C=C)\n",
    "        else:\n",
    "            query = \"target == '{}' & clf == '{}' \".format(target, clf_name)\n",
    "            C = float(C1.query(query)['select_C'])\n",
    "            clf.set_params(clf__C=C)\n",
    "\n",
    "    vot_clf.fit(target_train_data.Tweet, true_stances)\n",
    "\n",
    "    # predict on test data\n",
    "    index = test_data.Target == target\n",
    "    test_tweets = test_data.loc[index, 'Tweet']\n",
    "    test_data.loc[index, 'Stance'] = vot_clf.predict(test_tweets)\n",
    "\n",
    "    # predict on training data too to gauge overfitting\n",
    "    index = train_data.Target == target\n",
    "    train_tweets = train_data.loc[index, 'Tweet']\n",
    "    pred_stances = vot_clf.predict(train_tweets)\n",
    "\n",
    "    print classification_report(true_stances, pred_stances,\n",
    "                            digits=4)\n",
    "\n",
    "    macro_f = fbeta_score(true_stances, pred_stances, 1.0,\n",
    "                          labels=['AGAINST', 'FAVOR'], average='macro')\n",
    "\n",
    "    print 'macro-average of F-score(FAVOR) and F-score(AGAINST): {:.4f}\\n'.format(\n",
    "            macro_f)\n",
    "\n",
    "    # replace true stances in training data with predicted stances\n",
    "    train_data.loc[index, 'Stance'] = pred_stances\n",
    "\n",
    "\n",
    "print 80 * \"=\"\n",
    "print 'Overall'\n",
    "print 80 * \"=\"\n",
    "\n",
    "print classification_report(true_train_stances, train_data.Stance,\n",
    "                            digits=4)\n",
    "\n",
    "macro_f = fbeta_score(true_train_stances, train_data.Stance, 1.0,\n",
    "                      labels=['AGAINST', 'FAVOR'], average='macro')\n",
    "\n",
    "print 'macro-average of F-score(FAVOR) and F-score(AGAINST): {:.4f}\\n'.format(\n",
    "        macro_f)\n",
    "\n",
    "\n",
    "train_fname = 'run1_train.txt'\n",
    "print 'Writing ', train_fname\n",
    "train_data.to_csv(open(train_fname, 'w'), '\\t', encoding='utf-8',\n",
    "                  quoting=csv.QUOTE_NONE)\n",
    "\n",
    "test_fname = 'run1_test.txt'\n",
    "print 'Writing ', test_fname\n",
    "test_data.to_csv(open(test_fname, 'w'), '\\t', encoding='utf-8',\n",
    "                 quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}