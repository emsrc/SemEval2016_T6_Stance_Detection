{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp4 #\n",
    "\n",
    "Combining normal word features and Glove vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.cross_validation import cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(open('semeval2016-task6-trainingdata.txt'), '\\t', index_col=0)\n",
    "target_data = data[data.Target == 'Climate Change is a Real Concern']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(decode_error='ignore',\n",
    "                             lowercase=False,\n",
    "                             ngram_range=(2,2))\n",
    "bigram_vecs = vectorizer.fit_transform(target_data.Tweet)\n",
    "# convert to numpy.ndarray\n",
    "bigram_vecs = np.squeeze(np.asarray(bigram_vecs.todense()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(target_data.Stance, n_folds=5, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Vectorization is applied to the whole data set rather than part of the pipeline,\n",
    "# because it is a difficult to concatenate the glove vectors to training and testing folds. \n",
    "# However, this introduces features (vocab terms) in the training data whse value is always zero.\n",
    "# This seems to harm the classifier.\n",
    "# Therefore, we use VarianceThreshols to remove these features, which have zero variance.\n",
    "pipeline = Pipeline([('vect', VarianceThreshold()),\n",
    "                     ('clf', SVC(C=10, gamma=))\n",
    "                     #('clf', MultinomialNB())\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DIMENSION: 25\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.0000    0.0000    0.0000        15\n",
      "      FAVOR     0.6856    0.7406    0.7120       212\n",
      "       NONE     0.6446    0.6369    0.6407       168\n",
      "\n",
      "avg / total     0.6421    0.6684    0.6547       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.3560\n",
      "\n",
      "================================================================================\n",
      "DIMENSION: 50\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.0000    0.0000    0.0000        15\n",
      "      FAVOR     0.7040    0.7406    0.7218       212\n",
      "       NONE     0.6570    0.6726    0.6647       168\n",
      "\n",
      "avg / total     0.6573    0.6835    0.6701       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.3609\n",
      "\n",
      "================================================================================\n",
      "DIMENSION: 100\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     0.0000    0.0000    0.0000        15\n",
      "      FAVOR     0.7593    0.7736    0.7664       212\n",
      "       NONE     0.7039    0.7500    0.7262       168\n",
      "\n",
      "avg / total     0.7069    0.7342    0.7202       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.3832\n",
      "\n",
      "================================================================================\n",
      "DIMENSION: 200\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST     1.0000    0.0667    0.1250        15\n",
      "      FAVOR     0.7804    0.7877    0.7840       212\n",
      "       NONE     0.7333    0.7857    0.7586       168\n",
      "\n",
      "avg / total     0.7687    0.7595    0.7482       395\n",
      "\n",
      "macro-average of F-score(FAVOR) and F-score(AGAINST): 0.4545\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dim in 25, 50, 100, 200:\n",
    "    print 80 * '='\n",
    "    print 'DIMENSION:', dim\n",
    "    glove_vecs = pd.read_pickle('semeval2016-task6-trainingdata_climate_glove.twitter.27B.{}d.pkl'.format(dim))\n",
    "    assert (glove_vecs.index == target_data.Stance).all()\n",
    "    # NB can not deal with negative feature values, so rescale between (0,1) \n",
    "    #scaler = MinMaxScaler(copy=False)\n",
    "    #glove_vecs = scaler.fit_transform(glove_vecs)\n",
    "    bigram_glove_vecs = np.concatenate((bigram_vecs, glove_vecs), axis=1)\n",
    "    \n",
    "    pred_stances = cross_val_predict(pipeline, bigram_glove_vecs, target_data.Stance, cv=cv)\n",
    "    print classification_report(target_data.Stance, pred_stances, digits=4)\n",
    "\n",
    "    macro_f = fbeta_score(target_data.Stance, pred_stances, 1.0, \n",
    "                          labels=['AGAINST', 'FAVOR'], average='macro')\n",
    "    print 'macro-average of F-score(FAVOR) and F-score(AGAINST): {:.4f}\\n'.format(macro_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('vect', CountVectorizer(decode_error='ignore',\n",
    "                                              lowercase=False,\n",
    "                                              ngram_range=(2,2))),\n",
    "                     ('clf', MultinomialNB())])\n",
    "print pipeline\n",
    "\n",
    "pred_stances = cross_val_predict(pipeline, target_data.Tweet, target_data.Stance, cv=cv)\n",
    "print classification_report(target_data.Stance, pred_stances, digits=4)\n",
    "\n",
    "macro_f = fbeta_score(target_data.Stance, pred_stances, 1.0, \n",
    "                      labels=['AGAINST', 'FAVOR'], average='macro')\n",
    "print 'macro-average of F-score(FAVOR) and F-score(AGAINST): {:.4f}\\n'.\\\n",
    "format(macro_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
